{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embeddings : le modèle Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrainement d'un modèle Word2Vec sur ce corpus (modèle 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19min 5s, sys: 47.3 s, total: 19min 52s\n",
      "Wall time: 7min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = Word2Vec(\n",
    "    corpus, # On passe le corpus de ngrams que nous venons de créer\n",
    "    vector_size=32, # Le nombre de dimensions dans lesquelles le contexte des mots devra être réduit, aka. vector_size\n",
    "    window=5, # La taille du \"contexte\", ici 5 mots avant et après le mot observé\n",
    "    min_count=5, # On ignore les mots qui n'apparaissent pas au moins 5 fois dans le corpus\n",
    "    workers=4, # Permet de paralléliser l'entraînement du modèle en 4 threads\n",
    "    epochs=5 # Nombre d'itérations du réseau de neurones sur le jeu de données pour ajuster les paramètres avec la descende de gradient, aka. epochs.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explorer le modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec.load(\"../data/bulletins_2.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculer la similarité entre deux termes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86908996"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity(\"boucher\", \"boulanger\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.similarity(\"homme\", \"femme\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.similarity(\"voiture\", \"carrosse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chercher les mots les plus proches d'un terme donné"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('laeken', 0.8239486217498779),\n",
       " ('considere_comme_officiel', 0.7925914525985718),\n",
       " ('liege', 0.7702558040618896),\n",
       " ('paris', 0.7679300308227539),\n",
       " ('nivelles', 0.7521665096282959),\n",
       " ('gand', 0.7397889494895935),\n",
       " ('lille', 0.7102484703063965),\n",
       " ('differents_quartiers', 0.6752375960350037),\n",
       " ('lille_1860', 0.6710933446884155),\n",
       " ('louvain', 0.6700588464736938)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"bruxelles\", topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.most_similar(\"boucher\", topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Faire des recherches complexes à travers l'espace vectoriel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('lille', 0.8239251375198364), ('ostende', 0.8021267056465149), ('gand', 0.7774108052253723), ('manchester', 0.7756398320198059), ('londres', 0.7693049311637878), ('tournai', 0.7622190117835999), ('verviers', 0.7603538036346436), ('paris', 0.7556376457214355), ('louvain', 0.7518820762634277), ('prague', 0.7503906488418579)]\n"
     ]
    }
   ],
   "source": [
    "print(model.wv.most_similar(positive=['bruxelles', 'france'], negative=['belgique']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèle 3: Taille du vecteur = 100 (vs 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26min 12s, sys: 1min 6s, total: 27min 19s\n",
      "Wall time: 9min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = Word2Vec(\n",
    "    corpus, # On passe le corpus de ngrams que nous venons de créer\n",
    "    vector_size=100, # Le nombre de dimensions dans lesquelles le contexte des mots devra être réduit, aka. vector_size\n",
    "    window=5, # La taille du \"contexte\", ici 5 mots avant et après le mot observé\n",
    "    min_count=5, # On ignore les mots qui n'apparaissent pas au moins 5 fois dans le corpus\n",
    "    workers=4, # Permet de paralléliser l'entraînement du modèle en 4 threads\n",
    "    epochs=5 # Nombre d'itérations du réseau de neurones sur le jeu de données pour ajuster les paramètres avec la descende de gradient, aka. epochs.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec.load(\"../data/bulletins_3.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7806577"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity(\"boucher\", \"boulanger\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.similarity(\"homme\", \"femme\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.similarity(\"voiture\", \"carrosse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('rruxelles', 0.6470252275466919),\n",
       " ('paris', 0.6332045793533325),\n",
       " ('liege', 0.631273090839386),\n",
       " ('nivelles', 0.6280113458633423),\n",
       " ('gand', 0.6024729013442993),\n",
       " ('laeken', 0.5872405767440796),\n",
       " ('lille', 0.5851026773452759),\n",
       " ('bruxelle', 0.5699034929275513),\n",
       " ('jumeaux_naissances', 0.5477592945098877),\n",
       " ('malines', 0.5462380647659302)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"bruxelles\", topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.most_similar(\"boucher\", topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('lille', 0.6613479256629944), ('paris', 0.6434320211410522), ('verviers', 0.6389840841293335), ('londres', 0.6370319724082947), ('hambourg', 0.6282646059989929), ('prague', 0.6222774386405945), ('gand', 0.6142219305038452), ('tournai', 0.6134740114212036), ('liege', 0.6133009791374207), ('ostende', 0.6108174920082092)]\n"
     ]
    }
   ],
   "source": [
    "print(model.wv.most_similar(positive=['bruxelles', 'france'], negative=['belgique']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèle 4: Vecteur 100 + élargissement de la fenêtre à 20 (vs 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31min 2s, sys: 1min 10s, total: 32min 12s\n",
      "Wall time: 10min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = Word2Vec(\n",
    "    corpus, # On passe le corpus de ngrams que nous venons de créer\n",
    "    vector_size=100, # Le nombre de dimensions dans lesquelles le contexte des mots devra être réduit, aka. vector_size\n",
    "    window=20, # La taille du \"contexte\", ici 5 mots avant et après le mot observé\n",
    "    min_count=5, # On ignore les mots qui n'apparaissent pas au moins 5 fois dans le corpus\n",
    "    workers=4, # Permet de paralléliser l'entraînement du modèle en 4 threads\n",
    "    epochs=5 # Nombre d'itérations du réseau de neurones sur le jeu de données pour ajuster les paramètres avec la descende de gradient, aka. epochs.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec.load(\"../data/bulletins_4.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69779754"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity(\"boucher\", \"boulanger\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.similarity(\"homme\", \"femme\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('xelles', 0.6508788466453552),\n",
       " ('dette_active', 0.6217373609542847),\n",
       " ('bruxelle', 0.5955502390861511),\n",
       " ('liege', 0.586171567440033),\n",
       " ('laeken', 0.5658113956451416),\n",
       " ('nivelles', 0.559372067451477),\n",
       " ('hutel', 0.5444490909576416),\n",
       " ('vhotel', 0.5254800915718079),\n",
       " ('manufacturiere', 0.5184491276741028),\n",
       " ('bruxel', 0.5167596340179443)]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"bruxelles\", topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.most_similar(\"boucher\", topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('liege', 0.6075229048728943), ('manchester', 0.6038661599159241), ('hambourg', 0.5692122578620911), ('ostende', 0.5674587488174438), ('paris', 0.5573484897613525), ('lille', 0.5570899844169617), ('cologne', 0.5560243129730225), ('gand', 0.5556208491325378), ('amsterdam', 0.5449244976043701), ('tournai', 0.5420806407928467)]\n"
     ]
    }
   ],
   "source": [
    "print(model.wv.most_similar(positive=['bruxelles', 'france'], negative=['belgique']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèle 5: Taille fenêtre 20 (vs 5) et vecteur 32 (vs 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26min 43s, sys: 1min 14s, total: 27min 58s\n",
      "Wall time: 9min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = Word2Vec(\n",
    "    corpus, # On passe le corpus de ngrams que nous venons de créer\n",
    "    vector_size=32, # Le nombre de dimensions dans lesquelles le contexte des mots devra être réduit, aka. vector_size\n",
    "    window=20, # La taille du \"contexte\", ici 5 mots avant et après le mot observé\n",
    "    min_count=5, # On ignore les mots qui n'apparaissent pas au moins 5 fois dans le corpus\n",
    "    workers=4, # Permet de paralléliser l'entraînement du modèle en 4 threads\n",
    "    epochs=5 # Nombre d'itérations du réseau de neurones sur le jeu de données pour ajuster les paramètres avec la descende de gradient, aka. epochs.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec.load(\"../data/bulletins_5.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8505966"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity(\"boucher\", \"boulanger\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.similarity(\"homme\", \"femme\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('laeken', 0.8055386543273926),\n",
       " ('liege', 0.7914955615997314),\n",
       " ('gand', 0.7288044095039368),\n",
       " ('bruxelloise', 0.7005123496055603),\n",
       " ('aux_confins', 0.6939319372177124),\n",
       " ('nivelles', 0.6921486854553223),\n",
       " ('obbgations_tramways', 0.6838479042053223),\n",
       " ('ostende', 0.6827777624130249),\n",
       " ('paris', 0.6722395420074463),\n",
       " ('louvain', 0.6675084829330444)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"bruxelles\", topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.most_similar(\"boucher\", topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('liege', 0.8014519214630127), ('huy', 0.7924149632453918), ('gand', 0.7921144962310791), ('ostende', 0.7839378714561462), ('hambourg', 0.7556935548782349), ('manchester', 0.7534753680229187), ('lille', 0.7480643391609192), ('verviers', 0.7413298487663269), ('jadis', 0.7364925146102905), ('berlin', 0.735415518283844)]\n"
     ]
    }
   ],
   "source": [
    "print(model.wv.most_similar(positive=['bruxelles', 'france'], negative=['belgique']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèle 6 : Vecteur 300 et fenêtre 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 52min 11s, sys: 2min 14s, total: 54min 25s\n",
      "Wall time: 16min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = Word2Vec(\n",
    "    corpus, # On passe le corpus de ngrams que nous venons de créer\n",
    "    vector_size=300, # Le nombre de dimensions dans lesquelles le contexte des mots devra être réduit, aka. vector_size\n",
    "    window=10, # La taille du \"contexte\", ici 5 mots avant et après le mot observé\n",
    "    min_count=5, # On ignore les mots qui n'apparaissent pas au moins 5 fois dans le corpus\n",
    "    workers=4, # Permet de paralléliser l'entraînement du modèle en 4 threads\n",
    "    epochs=5 # Nombre d'itérations du réseau de neurones sur le jeu de données pour ajuster les paramètres avec la descende de gradient, aka. epochs.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec.load(\"../data/bulletins_6.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.similarity(\"boucher\", \"boulanger\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.similarity(\"homme\", \"femme\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24132355"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity(\"voiture\", \"carrosse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.most_similar(\"bruxelles\", topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tailleur', 0.6623472571372986),\n",
       " ('boulanger', 0.6560649275779724),\n",
       " ('cabaretier', 0.6487619280815125),\n",
       " ('menuisier', 0.6416441798210144),\n",
       " ('serrurier', 0.6407414078712463),\n",
       " ('charcutier', 0.6258613467216492),\n",
       " ('tapissier', 0.614556074142456),\n",
       " ('terrassier', 0.6109156012535095),\n",
       " ('cordonnier', 0.6100437641143799),\n",
       " ('fabricant', 0.6039721965789795)]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"boucher\", topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.wv.most_similar(positive=['bruxelles', 'france'], negative=['belgique']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèle 7 : 300 dimensions et élargissement de la fenêtre à 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 18min 26s, sys: 3min 23s, total: 1h 21min 49s\n",
      "Wall time: 23min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = Word2Vec(\n",
    "    corpus, # On passe le corpus de ngrams que nous venons de créer\n",
    "    vector_size=300, # Le nombre de dimensions dans lesquelles le contexte des mots devra être réduit, aka. vector_size\n",
    "    window=40, # La taille du \"contexte\", ici 5 mots avant et après le mot observé\n",
    "    min_count=5, # On ignore les mots qui n'apparaissent pas au moins 5 fois dans le corpus\n",
    "    workers=4, # Permet de paralléliser l'entraînement du modèle en 4 threads\n",
    "    epochs=5 # Nombre d'itérations du réseau de neurones sur le jeu de données pour ajuster les paramètres avec la descende de gradient, aka. epochs.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec.load(\"../data/bulletins_7.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.59319586"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity(\"boucher\", \"boulanger\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.similarity(\"homme\", \"femme\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1269484"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity(\"voiture\", \"carrosse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('liege', 0.5068586468696594),\n",
       " ('nivelles', 0.49116843938827515),\n",
       " ('bruxelle', 0.4783177375793457),\n",
       " ('xelles', 0.4692355692386627),\n",
       " ('tournai', 0.4536599814891815),\n",
       " ('lille', 0.44403088092803955),\n",
       " ('ostende', 0.44255688786506653),\n",
       " ('liruxelles', 0.4339611530303955),\n",
       " ('verviers', 0.43019574880599976),\n",
       " ('dette_active', 0.4301547706127167)]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"bruxelles\", topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('boulanger', 0.5931957364082336),\n",
       " ('marchand', 0.579157829284668),\n",
       " ('coiffeur', 0.5705497860908508),\n",
       " ('etre_abattus', 0.5697841644287109),\n",
       " ('fabricant', 0.5636791586875916),\n",
       " ('mecanicien', 0.5634440779685974),\n",
       " ('menuisier', 0.5607987642288208),\n",
       " ('cordonnier', 0.5579670071601868),\n",
       " ('serrurier', 0.5513495802879333),\n",
       " ('cabaretier', 0.5434521436691284)]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"boucher\", topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('liege', 0.5512763261795044), ('lille', 0.5193424820899963), ('tournai', 0.5141823291778564), ('ostende', 0.5015013217926025), ('huy', 0.48177802562713623), ('prague', 0.4748130738735199), ('gand', 0.47399699687957764), ('lyon', 0.46861395239830017), ('rotterdam', 0.4614550471305847), ('geneve', 0.45686960220336914)]\n"
     ]
    }
   ],
   "source": [
    "print(model.wv.most_similar(positive=['bruxelles', 'france'], negative=['belgique']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèle 8 : Vecteur 300, fenêtre 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 52min 31s, sys: 2min 45s, total: 55min 16s\n",
      "Wall time: 17min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = Word2Vec(\n",
    "    corpus, # On passe le corpus de ngrams que nous venons de créer\n",
    "    vector_size=300, # Le nombre de dimensions dans lesquelles le contexte des mots devra être réduit, aka. vector_size\n",
    "    window=5, # La taille du \"contexte\", ici 5 mots avant et après le mot observé\n",
    "    min_count=5, # On ignore les mots qui n'apparaissent pas au moins 5 fois dans le corpus\n",
    "    workers=4, # Permet de paralléliser l'entraînement du modèle en 4 threads\n",
    "    epochs=5 # Nombre d'itérations du réseau de neurones sur le jeu de données pour ajuster les paramètres avec la descende de gradient, aka. epochs.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec.load(\"../data/bulletins_8.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6921761"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity(\"boucher\", \"boulanger\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.similarity(\"homme\", \"femme\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20062777"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity(\"voiture\", \"carrosse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('nivelles', 0.5794664025306702),\n",
       " ('rruxelles', 0.5737338662147522),\n",
       " ('liege', 0.5225680470466614),\n",
       " ('gand', 0.5023678541183472),\n",
       " ('paris', 0.48170360922813416),\n",
       " ('xelles', 0.4629574120044708),\n",
       " ('malines', 0.4540492296218872),\n",
       " ('londres', 0.450400710105896),\n",
       " ('lille', 0.449739545583725),\n",
       " ('verviers', 0.44773247838020325)]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"bruxelles\", topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('menuisier', 0.705475926399231),\n",
       " ('tailleur', 0.7049712538719177),\n",
       " ('cordonnier', 0.6925906538963318),\n",
       " ('boulanger', 0.6921761631965637),\n",
       " ('charcutier', 0.6875828504562378),\n",
       " ('tapissier', 0.6866316795349121),\n",
       " ('serrurier', 0.67592453956604),\n",
       " ('marbrier', 0.657673180103302),\n",
       " ('cabaretier', 0.6564407348632812),\n",
       " ('batelier', 0.6554194092750549)]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"boucher\", topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('verviers', 0.534920334815979), ('londres', 0.5326730608940125), ('liege', 0.5236067175865173), ('tournai', 0.5141814947128296), ('gand', 0.5092669129371643), ('hambourg', 0.4946388006210327), ('nivelles', 0.4940313696861267), ('paris', 0.4934212565422058), ('prague', 0.4888829290866852), ('lille', 0.4820585250854492)]\n"
     ]
    }
   ],
   "source": [
    "print(model.wv.most_similar(positive=['bruxelles', 'france'], negative=['belgique']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèle 9 : Vecteur 100, fenêtre 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 42min 18s, sys: 2min 4s, total: 44min 23s\n",
      "Wall time: 14min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = Word2Vec(\n",
    "    corpus, # On passe le corpus de ngrams que nous venons de créer\n",
    "    vector_size=100, # Le nombre de dimensions dans lesquelles le contexte des mots devra être réduit, aka. vector_size\n",
    "    window=40, # La taille du \"contexte\", ici 5 mots avant et après le mot observé\n",
    "    min_count=5, # On ignore les mots qui n'apparaissent pas au moins 5 fois dans le corpus\n",
    "    workers=4, # Permet de paralléliser l'entraînement du modèle en 4 threads\n",
    "    epochs=5 # Nombre d'itérations du réseau de neurones sur le jeu de données pour ajuster les paramètres avec la descende de gradient, aka. epochs.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec.load(\"../data/bulletins_9.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68535304"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity(\"boucher\", \"boulanger\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.similarity(\"homme\", \"femme\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12812918"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity(\"voiture\", \"carrosse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('xelles', 0.6651670336723328),\n",
       " ('liege', 0.5861473083496094),\n",
       " ('nivelles', 0.5695111155509949),\n",
       " ('laeken', 0.563617467880249),\n",
       " ('dette_active', 0.5545754432678223),\n",
       " ('bruxelle', 0.5514754056930542),\n",
       " ('bruxe', 0.540813148021698),\n",
       " ('manufacturiere', 0.5400780439376831),\n",
       " ('huy', 0.5379692316055298),\n",
       " ('ostende', 0.5323569774627686)]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"bruxelles\", topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cordonnier', 0.7136046290397644),\n",
       " ('fabricant', 0.695364773273468),\n",
       " ('boulanger', 0.6853529810905457),\n",
       " ('charpentier', 0.6758134365081787),\n",
       " ('marchand', 0.6743961572647095),\n",
       " ('serrurier', 0.6743265390396118),\n",
       " ('menuisier', 0.6717424988746643),\n",
       " ('charcutier', 0.6633214950561523),\n",
       " ('tailleur', 0.656404435634613),\n",
       " ('meunier', 0.6544731855392456)]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"boucher\", topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('huy', 0.6195623278617859), ('hambourg', 0.5991153717041016), ('manchester', 0.5982712507247925), ('liege', 0.5854235887527466), ('londres', 0.5793405175209045), ('ostende', 0.5688986778259277), ('paris', 0.5649790167808533), ('lille', 0.5636627674102783), ('amsterdam', 0.5562283992767334), ('gand', 0.5400305390357971)]\n"
     ]
    }
   ],
   "source": [
    "print(model.wv.most_similar(positive=['bruxelles', 'france'], negative=['belgique']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
